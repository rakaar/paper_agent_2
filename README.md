# Paper Explainer

This project automates the process of converting academic papers (PDFs or any long-form text) into concise, narrated video presentations. It leverages Large Language Models (LLMs) to summarize content into slide-friendly formats, Text-to-Speech (TTS) for narration, and various tools for generating visual slides and combining them with audio into a video.

## Directory Layout

```
paper-explainer/
│
├─ slides/                 # All auto-generated artifacts land here
│   ├─ deck.md             # Marp Markdown (source of truth for slides)
│   ├─ frames/             # PNG images of each slide (e.g., deck.001.png, deck.002.png, …)
│   ├─ audio/              # WAV audio files for each slide's narration (e.g., slide01.wav, slide02.wav, …)
│   ├─ <original_filename>_slides_plan.json # Structured JSON output from LLM
│   ├─ <original_filename>_audio_script.txt # Plain text narration script
│   └─ video.mp4           # Final generated video
│
├─ pdf2json.py             # Helper for interacting with Gemini LLM
├─ json2marp.py            # Converts LLM's JSON output to Marp Markdown
├─ txt2slides.py           # Main script: orchestrates the entire pipeline
├─ requirements.txt        # Python dependencies
├─ .gitignore              # Specifies files/directories to ignore in Git
└─ README.md               # This file
```

## Core Components & What They Do

*   **`pdf2json.py`**: This file contains the `call_llm` helper function, which is responsible for sending prompts to the Gemini 2.5 Pro LLM and returning its raw JSON response. It handles authentication, retries, and model selection internally.

*   **`json2marp.py`**: This script takes the structured JSON output from the LLM (generated by `txt2slides.py`) and converts it into Marp Markdown format. Marp Markdown is a specialized Markdown syntax for creating slide decks, with built-in support for MathJax for rendering mathematical equations.

*   **`txt2slides.py`**: This is the main orchestration script for the entire pipeline. It performs the following steps:
    1.  Reads and combines content from one or more input plain-text (`.txt`) files.
    2.  Constructs a prompt for the Gemini LLM, instructing it to break the text into a specified number of slides (currently 2 slides per input text file) with concise content and detailed audio narration.
    3.  Calls `pdf2json.py` to interact with the LLM and get the structured slide data.
    4.  Saves the raw LLM output as a JSON file (`slides/<original_filename>_slides_plan.json`).
    5.  Calls `json2marp.py` to convert the LLM's JSON into a Marp Markdown file (`slides/deck.md`).
    6.  Generates audio narration files (`slides/audio/slideXX.wav`) for each slide using Sarvam AI's Text-to-Speech (TTS) service.
    7.  Renders the Marp Markdown file into individual PNG image frames (`slides/frames/deck.00X.png`) using the `marp-cli` tool.
    8.  Combines the generated PNG frames and audio files into a single MP4 video (`slides/video.mp4`) using `ffmpeg`.

*   **`requirements.txt`**: Lists all Python libraries required for this project. These can be installed using `pip`.

*   **`.gitignore`**: Configured to ignore temporary files, virtual environments, and all generated output files, ensuring a clean Git repository.

## Setup

To set up and run this project, you'll need Python, Node.js (for `marp-cli`), and `ffmpeg` installed on your system.

### 1. Clone the Repository

```bash
git clone <repository_url>
cd paper-explainer
```

### 2. Python Environment Setup

It's highly recommended to use a virtual environment to manage Python dependencies.

```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: .\venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Install Node.js and Marp CLI

`marp-cli` is a Node.js package that converts Marp Markdown to various formats, including PNGs. It requires Node.js (version 18 or higher is recommended).

```bash
# Install Node.js (if not already installed) - refer to Node.js official documentation for your OS
# Example for Ubuntu:
# sudo apt update
# sudo apt install nodejs npm

# Install marp-cli globally
npm i -g @marp-team/marp-cli
```

### 4. Install FFmpeg

FFmpeg is a powerful command-line tool used for handling multimedia files. It's essential for combining the image frames and audio into a video.

```bash
# On Debian/Ubuntu:
sudo apt update
sudo apt install ffmpeg

# On Fedora:
sudo dnf install ffmpeg

# On Arch Linux:
sudo pacman -S ffmpeg

# For other operating systems, refer to the official FFmpeg website or your system's documentation.
```

### 5. Set API Keys

This project uses API keys for Gemini (via `pdf2json.py`) and Sarvam AI (for TTS). **Never hardcode your API keys in the source code.** Instead, set them as environment variables.

*   **`GEMINI_API_KEY`**: Your API key for Google Gemini.
*   **`SARVAM_API_KEY`**: Your API key for Sarvam AI.

**Example (Linux/macOS):**

```bash
export GEMINI_API_KEY="YOUR_GEMINI_API_KEY"
export SARVAM_API_KEY="YOUR_SARVAM_API_KEY"
```

**Example (Windows Command Prompt):**

```cmd
set GEMINI_API_KEY="YOUR_GEMINI_API_KEY"
set SARVAM_API_KEY="YOUR_SARVAM_API_KEY"
```

For persistent environment variables, refer to your operating system's documentation.

## Usage

To run the pipeline, execute the `txt2slides.py` script with one or more plain-text (`.txt`) files as arguments.

```bash
source venv/bin/activate # Activate your virtual environment
python txt2slides.py paper_structured_page_1.txt paper_structured_page_2.txt
```

### What You Get

After successful execution, the `slides/` directory will contain:

*   **`deck.md`**: The Marp Markdown file generated from the LLM's output.
*   **`frames/`**: A directory containing PNG images of each slide (e.g., `deck.001.png`, `deck.002.png`).
*   **`audio/`**: A directory containing WAV audio files for each slide's narration (e.g., `slide01.wav`, `slide02.wav`).
*   **`<original_filename>_slides_plan.json`**: A JSON file containing the structured data for each slide (title, content, audio script) as returned by the LLM.
*   **`<original_filename>_audio_script.txt`**: A plain text file containing the concatenated narration script for all slides.
*   **`video.mp4`**: The final MP4 video presentation, combining the slide images and their respective audio narrations.

## Troubleshooting

*   **`ModuleNotFoundError`**: Ensure your virtual environment is activated and all dependencies are installed (`pip install -r requirements.txt`).
*   **`marp` CLI not found**: Ensure Node.js and `marp-cli` are installed globally (`npm i -g @marp-team/marp-cli`).
*   **`ffmpeg` not found**: Ensure FFmpeg is installed on your system and accessible from your PATH.
*   **API Key Errors**: Double-check that your `GEMINI_API_KEY` and `SARVAM_API_KEY` environment variables are correctly set.
*   **Empty `frames/` directory**: If Marp runs but no PNGs are generated, check the console output for any warnings or errors from `marp-cli`. Ensure `--allow-local-files` is used if your Markdown references local images.

Feel free to explore and modify the scripts to suit your specific needs!